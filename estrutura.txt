# Template para An√°lise de Sequestro de Carbono

# üì¶ Etapa 1: Importa√ß√£o de bibliotecas e leitura dos dados
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler

# Adicional
import warnings
warnings.filterwarnings("ignore")

# üîç Etapa 2: Carregar e explorar os dados
# df = pd.read_csv("dados_sequestro_carbono.csv")  # considere : para rebanhos 
    # Carregar dados dos rebanhos
    def carregar_dados_rebanho():
        try:
            # Carregar dados do IBGE
            df_rebanho = pd.read_csv('data/dados_rebanho/br_ibge_ppm_efetivo_rebanhos.csv', sep=';')
            df_municipios = pd.read_csv('data/dados_rebanho/br_bd_diretorios_brasil_municipio.csv')
            
            # Filtrar apenas dados do MS
            df_rebanho = df_rebanho[df_rebanho['sigla_uf'] == 'MS']
            
            # Mesclar com dados dos munic√≠pios
            df_rebanho = pd.merge(df_rebanho, 
                                 df_municipios[['id_municipio', 'nome']], 
                                 on='id_municipio', 
                                 how='left')
            
            return df_rebanho
        except Exception as e:
            st.error(f'Erro ao carregar dados dos rebanhos: {str(e)}')
            return None

    def plot_evolucao_rebanho(df):
        # Agrupar por ano e tipo de rebanho
        df_evolucao = df.groupby(['ano', 'tipo_rebanho'])['quantidade'].sum().reset_index()
        
# df.head()
para dados meteorol√≥gicos 
st.set_page_config(page_title="An√°lise Meteorol√≥gica", layout="wide")
st.title("An√°lise Meteorol√≥gica por Cidade")

# Fun√ß√£o para extrair informa√ß√µes da cidade do arquivo
def get_city_info(file_path):
    info = {'nome': None, 'latitude': None, 'longitude': None}
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line_lower = line.lower()
            if 'nome:' in line_lower:
                info['nome'] = line.split(':')[1].strip()
            elif 'latitude:' in line_lower:
                info['latitude'] = float(line.split(':')[1].strip())
            elif 'longitude:' in line_lower:
                info['longitude'] = float(line.split(':')[1].strip())
    return info

# Fun√ß√£o para ler e processar os dados meteorol√≥gicos
def process_meteo_data(file_path):
    # Pular as primeiras 10 linhas e ler o restante como CSV
    df = pd.read_csv(file_path, skiprows=10, sep=';')
    
    # Mapear os nomes das colunas corretamente
    colunas_esperadas = {
        'Data Medicao': 'Data',
        'NUMERO DE DIAS COM PRECIP. PLUV, MENSAL (AUT)(n√∫mero)': 'DiasPrecipitacao',
        'PRECIPITACAO TOTAL, MENSAL (AUT)(mm)': 'PrecipitacaoTotal',
        'PRESSAO ATMOSFERICA, MEDIA MENSAL (AUT)(mB)': 'PressaoAtmosferica',
        'TEMPERATURA MEDIA, MENSAL (AUT)(¬∞C)': 'TemperaturaMedia',
        'VENTO, VELOCIDADE MAXIMA MENSAL (AUT)(m/s)': 'VentoVelocidadeMaxima',
        'VENTO, VELOCIDADE MEDIA MENSAL (AUT)(m/s)': 'VentoVelocidadeMedia'
    }
    
    # Renomear as colunas usando o mapeamento
    df = df.rename(columns=colunas_esperadas)
    
    # Converter a coluna de data
    df['Data'] = pd.to_datetime(df['Data'])
    df['Mes'] = df['Data'].dt.month
    
    # Converter valores nulos ('null') para NaN
    df = df.replace('null', pd.NA)
    
    # Converter colunas para tipo num√©rico
    colunas_numericas = df.columns.drop(['Data', 'Mes'])
    for col in colunas_numericas:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    return df

# Caminho para a pasta de dados meteorol√≥gicos
data_dir = Path('data/dados_meteorologicos')
 e para dados agr√≠colas # Construir caminho compat√≠vel com todos os SOs
file_path = os.path.join("data", "dados_agricolas", "producao_qtde_produzida.xlsx")

# Verificar se o arquivo existe
if not os.path.exists(file_path):
    st.error(f"Arquivo n√£o encontrado: {file_path}")
    st.stop()

# Carregar os dados
df = pd.read_excel(file_path, header=None)

# Lista de produtos desejados
produtos_desejados = ['Soja', 'Algod√£o', 'Caf√©', 'Laranja', 'Cana de a√ß√∫car', 'Gr√£os', 'Madeira para papel', 'Milho']
 
# üìä Etapa 3: An√°lise Descritiva
# df.describe()
# df.info()
# df.isnull().sum()

# Correla√ß√£o
# plt.figure(figsize=(10, 8))
# sns.heatmap(df.corr(), annot=True, cmap='viridis')
# plt.title("Mapa de Correla√ß√£o")
# plt.show()

# üìà Etapa 4: Visualiza√ß√µes
# Gr√°fico de s√©rie temporal
# px.line(df, x='ano', y='sequestro_carbono', color='municipio')

# Dispers√£o entre produ√ß√£o agr√≠cola e sequestro
# px.scatter(df, x='quantidade_agricola', y='sequestro_carbono', color='municipio')

# üåø Etapa 5: Pr√©-processamento
# df = df.dropna()
# X = df.drop(columns=['sequestro_carbono'])
# y = df['sequestro_carbono']

# scaler = StandardScaler()
# X_scaled = scaler.fit_transform(X.select_dtypes(include=np.number))

# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# ü§ñ Etapa 6: Modelagem
# model = RandomForestRegressor(random_state=42)
# model.fit(X_train, y_train)
# y_pred = model.predict(X_test)

# üìâ Etapa 7: Avalia√ß√£o
# print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
# print("MAE:", mean_absolute_error(y_test, y_pred))
# print("R¬≤:", r2_score(y_test, y_pred))

# Import√¢ncia das vari√°veis
# importances = pd.Series(model.feature_importances_, index=X.select_dtypes(include=np.number).columns)
# importances.sort_values().plot(kind='barh', figsize=(10,6))
# plt.title("Import√¢ncia das Vari√°veis")
# plt.show()

# üîÆ Etapa 8: Simula√ß√£o de cen√°rio
# Exemplo: aumento de 10% em uma vari√°vel
# novo_exemplo = X_test[0].copy()
# novo_exemplo["quantidade_agricola"] *= 1.10
# pred_simulado = model.predict([novo_exemplo])

# print("Predi√ß√£o com cen√°rio simulado:", pred_simulado)

# ‚úÖ Etapa 9: Conclus√£o
# Escreva aqui sua an√°lise final com base nos resultados obtidos
